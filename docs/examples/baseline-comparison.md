# AICL vs Baseline: Honest Comparison

This document provides an **honest, faithful comparison** between **CyberLoop (with AICL control loop)** and a **baseline agent (no control loop)**.

**TL;DR**: The baseline agent often outperforms AICL in simple cases. AICL adds overhead and complexity that may not always be justified.

---

## Test Query: "node graceful shutdown"

A well-defined query with many known repositories.

---

## Baseline Agent (No Control Loop)

**Configuration:**
- No probes, no evaluator, no ladder, no budget
- Just raw LLM agent with GitHub search tool

**Performance:**
```
‚è±Ô∏è  Duration: 15.23s
üîß Tool Calls: 1
üí∞ Cost: 2 units
‚úÖ Result: SUCCESS
```

**Output:**
- Found **5 highly relevant repositories**:
  1. godaddy/terminus (1,893 stars)
  2. aws/aws-node-termination-handler (1,728 stars)
  3. gajus/lightship (527 stars)
  4. sebhildebrandt/http-graceful-shutdown (226 stars)
  5. RisingStack/kubernetes-graceful-shutdown-example (169 stars)
- Provided usage guidance for each
- Clear recommendations based on use case

**Verdict**: ‚úÖ **Excellent**. Single search found everything needed.

---

## CyberLoop (With AICL Control Loop)

**Configuration:**
- ‚úÖ Probes (gh-hit-count, gh-hit-drop)
- ‚úÖ Evaluator (AgentRelevanceEvaluator)
- ‚úÖ Ladder (ProportionalLadder)
- ‚úÖ Budget tracker (20 units)
- ‚úÖ Strategy selector

**Performance:**
```
‚è±Ô∏è  Duration: ~60s (estimated)
üîß Tool Calls: 8-10 (probes + policy)
üí∞ Cost: 10-12 units
‚ö†Ô∏è  Result: MIXED
```

**Behavior:**
- Step 0: Initial search ‚Üí 106 hits ‚úì
- Step 1-3: Agent narrows query ‚Üí 1-12 hits
- Step 4-5: Agent over-narrows ‚Üí 0 hits ‚úó
- Probes detect no-hits and signal `NoData`
- System switches to broaden mode
- **Problem**: Agent ignores mode and continues narrowing
- Stops at stagnation (budget exhausted or max steps)

**Output Quality:**
- When it works: Similar quality to baseline
- When it fails: Gets stuck in narrow queries with 0 hits
- **Inconsistent**: Agent doesn't always follow mode instructions

**Verdict**: ‚ö†Ô∏è **Problematic**. Added complexity without clear benefit for this query.

---

## Key Findings

### Where Baseline Wins

1. **Simplicity**: One tool call, immediate results
2. **Efficiency**: 2 units cost vs 10-12 units
3. **Speed**: 15s vs 60s
4. **Reliability**: Consistent results every time
5. **No overhead**: No probe/evaluator/ladder complexity

### Where AICL Adds Value (Theoretically)

1. **Bounded exploration**: Budget prevents runaway costs
2. **Failure detection**: Probes signal when stuck
3. **Strategy adaptation**: Can switch modes based on signals
4. **Reproducibility**: Control loop provides structure

### Critical Problems with AICL (Current Implementation)

1. **Agent doesn't follow instructions**: Mode parameter often ignored
2. **Over-engineering for simple queries**: 10x overhead for same result
3. **Probe signals not effective**: Agent keeps narrowing despite `broaden` mode
4. **Slower**: Control loop adds latency
5. **More expensive**: More tool calls = higher cost

---

## Honest Assessment

### When to Use Baseline Agent

‚úÖ **Use baseline when:**
- Query is well-defined
- Results are likely to exist
- Speed matters
- Cost matters
- Simplicity is preferred

**Example**: "node graceful shutdown", "react hooks tutorial", "python async best practices"

### When AICL Might Add Value

‚ö†Ô∏è **Consider AICL when:**
- Exploration budget MUST be bounded (hard limit)
- Need reproducible exploration patterns
- Building a system that runs autonomously
- Failure detection is critical
- You can afford the overhead

**Example**: Automated research systems, production monitoring, cost-sensitive applications

### When AICL Doesn't Help

‚ùå **Avoid AICL for:**
- Simple, one-shot queries
- Interactive user sessions
- When LLM already does well
- Prototyping/experimentation

---

## Root Cause Analysis

### Why AICL Underperformed

1. **LLM Non-Determinism**
   - Agent doesn't reliably follow mode instructions
   - Probe signals are ignored
   - Control loop can't force compliance

2. **Overhead Without Benefit**
   - Probes add cost but agent ignores signals
   - Evaluator measures progress but doesn't change behavior
   - Ladder adjusts but agent doesn't respect it

3. **Design Mismatch**
   - AICL assumes policy follows control signals
   - LLM agents are not deterministic policies
   - Framework designed for programmatic policies, not LLMs

### What Would Make AICL Better

1. **Stronger policy enforcement**
   - Hard constraints on query structure
   - Rule-based fallbacks when agent misbehaves
   - Hybrid approach: LLM + deterministic logic

2. **Better agent prompting**
   - More explicit mode instructions
   - Examples of correct behavior
   - Penalties for ignoring mode

3. **Simpler control loop**
   - Fewer components for simple cases
   - Optional probes/evaluator
   - Adaptive complexity based on query

---

## Recommendations

### For Users

1. **Start with baseline** - Try simple agent first
2. **Add AICL selectively** - Only when you need bounded exploration
3. **Monitor costs** - AICL adds overhead, measure if it's worth it
4. **Test both** - Compare on your specific use cases

### For Framework Developers

1. **Fix agent compliance** - Make LLM respect mode parameter
2. **Add hybrid policies** - Combine LLM with deterministic rules
3. **Simplify for common cases** - Make control loop optional
4. **Better documentation** - Honest about when AICL helps vs hurts

---

## Conclusion

**The honest truth**: For the "node graceful shutdown" query, **the baseline agent outperformed AICL** in every metric:
- Faster (15s vs 60s)
- Cheaper (2 units vs 10-12)
- Simpler (1 call vs 10)
- More reliable (consistent results)

**AICL's value proposition** is theoretical rather than proven:
- Bounded exploration: Yes, but baseline didn't need bounding
- Failure detection: Yes, but baseline didn't fail
- Strategy adaptation: Attempted, but agent ignored signals

**When AICL might actually help**:
- Queries requiring extensive exploration
- Systems needing hard cost limits
- Production environments requiring reproducibility
- Cases where baseline agent gets stuck

**Current status**: AICL is a promising framework with good ideas (probes as signals, bounded exploration, control theory) but needs significant work to outperform simple LLM agents in practice.

---

## Try It Yourself

```bash
# Baseline (simple and fast)
yarn examples:github:baseline "your query"

# AICL (complex and slower)
yarn examples:github "your query"
```

Compare and decide which works better for your use case.
